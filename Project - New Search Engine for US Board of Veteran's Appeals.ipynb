{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a85e3eb",
   "metadata": {},
   "source": [
    "# Legal Data Science and Informatics\n",
    "\n",
    "Author: Isaac Misael OlguÃ­n Nolasco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0777607",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df37aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "import chardet\n",
    "import codecs\n",
    "import importlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.symbols import ORTH\n",
    "from spacy.language import Language\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import plot_confusion_matrix as plot_confusion_matrix_sklearn\n",
    "\n",
    "import luima_sbd.sbd_utils as sbd_utils\n",
    "import config.project_config as project_config\n",
    "import config.sentences_custom as sentences_custom\n",
    "\n",
    "import fasttext\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce36749",
   "metadata": {},
   "source": [
    "## Reading of the dataset and general info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3af670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "dataset_path = './ldsi_w21_curated_annotations_v2.json'\n",
    "\n",
    "# Read file \n",
    "dataset_json = json.load(open(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35b0de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'annotations', 'types'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print keys\n",
    "dataset_json.keys() # dict_keys(['documents', 'annotations', 'types'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc4794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the curated dataset 3\n",
      "Total of documents in the dataset is 540\n",
      "Total of annotations in the dataset is 15349\n",
      "Total of types in the dataset is 14\n"
     ]
    }
   ],
   "source": [
    "# Print length of the dataset\n",
    "print(f'Length of the curated dataset {len(dataset_json)}')\n",
    "\n",
    "#Print length of 'documents'\n",
    "print(f'Total of documents in the dataset is {len(dataset_json[\"documents\"])}')\n",
    "\n",
    "#Print length of 'annotations'\n",
    "print(f'Total of annotations in the dataset is {len(dataset_json[\"annotations\"])}')\n",
    "\n",
    "#Print length of 'types'\n",
    "print(f'Total of types in the dataset is {len(dataset_json[\"types\"])}')\n",
    "#print(f'Types in the dataset are {dataset_json[\"types\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c556c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorthands dictionaries (taken from the LDSI_WS21_Classifier_Workshop)\n",
    "\n",
    "annotations = dataset_json['annotations']\n",
    "documents_by_id = {d['_id']: d for d in dataset_json['documents']}\n",
    "types_by_id = {t['_id']: t for t in dataset_json['types']}\n",
    "type_ids_by_name = {t['name']: t['_id'] for t in dataset_json['types']}\n",
    "type_names_by_id = {t['_id']: t['name'] for t in dataset_json['types']}\n",
    "doc_id_by_name = {d['name']: d['_id'] for d in dataset_json['documents']}\n",
    "doc_name_by_id = {d['_id']: d['name'] for d in dataset_json['documents']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd0d65",
   "metadata": {},
   "source": [
    "# Phase 1 - Dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d957f",
   "metadata": {},
   "source": [
    "## Getting the granted, denied and remanded cases\n",
    "\"\"\"\n",
    "print(len(annotations))\n",
    "print('-'*60)\n",
    "print(len(documents_by_id))\n",
    "print('-'*60)\n",
    "print(len(types_by_id))\n",
    "print(type_ids_by_name.keys())\n",
    "print('-'*60)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1202a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '61bb066d97ad59b4cfc4699a', 'start': 15922, 'end': 16078, 'document': '61aea57397ad59b4cfc41399', 'type': '61aeaf8097ad59b4cfc416d7'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_json[\"annotations\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70efa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents with annotations 141\n"
     ]
    }
   ],
   "source": [
    "docs_with_annotations = []\n",
    "for docId in documents_by_id:\n",
    "    for annotId in annotations:\n",
    "        if annotId['document'] == docId:\n",
    "            docs_with_annotations.append(docId)\n",
    "            break\n",
    "            \n",
    "print(f'Total number of documents with annotations {len(docs_with_annotations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f0ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_decision = {\"granted\": [], \"denied\":[], \"remanded\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e305cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70 granted, 71 denied and, 0 remanded cases\n"
     ]
    }
   ],
   "source": [
    "docs_decision[\"granted\"] = [doc for doc in docs_with_annotations if documents_by_id.get(doc)[\"outcome\"] == \"granted\"]\n",
    "docs_decision[\"denied\"] = [doc for doc in docs_with_annotations if documents_by_id.get(doc)[\"outcome\"] == \"denied\"]\n",
    "docs_decision[\"remanded\"] = [doc for doc in docs_with_annotations if documents_by_id.get(doc)[\"outcome\"] == \"remanded\"]\n",
    "print(f'There are {len(docs_decision[\"granted\"])} granted, {len(docs_decision[\"denied\"])} denied and, {len(docs_decision[\"remanded\"])} remanded cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aff3b0",
   "metadata": {},
   "source": [
    "## Sampling randomly test , dev and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9514919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the test_set 14\n",
      "Length of the dev_set 14\n",
      "Length of the training_set 113\n"
     ]
    }
   ],
   "source": [
    "test_set = []\n",
    "training_set = []\n",
    "dev_set = []\n",
    "\n",
    "test_set.extend(random.sample(docs_decision[\"granted\"], 7))\n",
    "test_set.extend(random.sample(docs_decision[\"denied\"], 7))\n",
    "\n",
    "docsGrantedAux = [x for x in docs_decision[\"granted\"] if x not in test_set]\n",
    "docsDeniedAux = [x for x in docs_decision[\"denied\"] if x not in test_set]\n",
    "\n",
    "dev_set.extend(random.sample(docsGrantedAux, 7))\n",
    "dev_set.extend(random.sample(docsDeniedAux, 7))\n",
    "\n",
    "docsGrantedAux = [x for x in docsGrantedAux if x not in dev_set]\n",
    "docsDeniedAux = [x for x in docsDeniedAux if x not in dev_set]\n",
    "\n",
    "training_set.extend(docsGrantedAux)\n",
    "training_set.extend(docsDeniedAux)\n",
    "\n",
    "print(f'Length of the test_set {len(test_set)}')\n",
    "print(f'Length of the dev_set {len(dev_set)}')\n",
    "print(f'Length of the training_set {len(training_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f25c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID's of the 14 documents for the test set\n",
      "\tIndex 0 with ID 61aea55c97ad59b4cfc4129e\n",
      "\tIndex 1 with ID 61aea55d97ad59b4cfc412b5\n",
      "\tIndex 2 with ID 61aea55f97ad59b4cfc41319\n",
      "\tIndex 3 with ID 61aea55c97ad59b4cfc41299\n",
      "\tIndex 4 with ID 61aea55e97ad59b4cfc412de\n",
      "\tIndex 5 with ID 61aea55d97ad59b4cfc412d3\n",
      "\tIndex 6 with ID 61aea55c97ad59b4cfc412af\n",
      "\tIndex 7 with ID 61aea57397ad59b4cfc4138f\n",
      "\tIndex 8 with ID 61aea57497ad59b4cfc413c9\n",
      "\tIndex 9 with ID 61aea57097ad59b4cfc4135b\n",
      "\tIndex 10 with ID 61aea57097ad59b4cfc4135a\n",
      "\tIndex 11 with ID 61aea57497ad59b4cfc413e8\n",
      "\tIndex 12 with ID 61aea57497ad59b4cfc413e7\n",
      "\tIndex 13 with ID 61aea57197ad59b4cfc41375\n",
      "ID's of the 14 documents for the dev set\n",
      "\tIndex 0 with ID 61aea55f97ad59b4cfc4130e\n",
      "\tIndex 1 with ID 61aea55c97ad59b4cfc412ac\n",
      "\tIndex 2 with ID 61aea55f97ad59b4cfc41304\n",
      "\tIndex 3 with ID 61aea55d97ad59b4cfc412bd\n",
      "\tIndex 4 with ID 61aea55e97ad59b4cfc412df\n",
      "\tIndex 5 with ID 61aea55e97ad59b4cfc412d4\n",
      "\tIndex 6 with ID 61aea55c97ad59b4cfc412a3\n",
      "\tIndex 7 with ID 61aea57497ad59b4cfc413e1\n",
      "\tIndex 8 with ID 61aea56f97ad59b4cfc41343\n",
      "\tIndex 9 with ID 61aea57497ad59b4cfc413ba\n",
      "\tIndex 10 with ID 61aea57197ad59b4cfc4136e\n",
      "\tIndex 11 with ID 61aea57397ad59b4cfc41391\n",
      "\tIndex 12 with ID 61aea57197ad59b4cfc41376\n",
      "\tIndex 13 with ID 61aea56f97ad59b4cfc4134c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"   \\nprint(f'IDs of the {len(training_set)} documents for the training set')\\nfor index, idDoc in enumerate(training_set):\\n    print(f'\\tIndex {index} with ID {idDoc}')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ID's of the 14 documents for the test set\")\n",
    "for index, idDoc in enumerate(test_set):\n",
    "    print(f'\\tIndex {index} with ID {idDoc}')\n",
    "    \n",
    "print(\"ID's of the 14 documents for the dev set\")\n",
    "for index, idDoc in enumerate(dev_set):\n",
    "    print(f'\\tIndex {index} with ID {idDoc}')\n",
    "    \n",
    "\"\"\"   \n",
    "print(f'IDs of the {len(training_set)} documents for the training set')\n",
    "for index, idDoc in enumerate(training_set):\n",
    "    print(f'\\tIndex {index} with ID {idDoc}')\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d97a15ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs of the training set are : ['61aea55c97ad59b4cfc41290', '61aea55c97ad59b4cfc41297', '61aea55c97ad59b4cfc41299', '61aea55c97ad59b4cfc4129b', '61aea55c97ad59b4cfc4129d', '61aea55c97ad59b4cfc4129e', '61aea55c97ad59b4cfc4129f', '61aea55c97ad59b4cfc412a0', '61aea55c97ad59b4cfc412a1', '61aea55c97ad59b4cfc412a3', '61aea55c97ad59b4cfc412a4', '61aea55c97ad59b4cfc412a6', '61aea55c97ad59b4cfc412aa', '61aea55c97ad59b4cfc412af', '61aea55d97ad59b4cfc412b5', '61aea55d97ad59b4cfc412b7', '61aea55d97ad59b4cfc412bc', '61aea55d97ad59b4cfc412bd', '61aea55d97ad59b4cfc412bf', '61aea55d97ad59b4cfc412c1', '61aea55d97ad59b4cfc412c7', '61aea55d97ad59b4cfc412cb', '61aea55d97ad59b4cfc412cd', '61aea55d97ad59b4cfc412d2', '61aea55d97ad59b4cfc412d3', '61aea55e97ad59b4cfc412d4', '61aea55e97ad59b4cfc412d5', '61aea55e97ad59b4cfc412d7', '61aea55e97ad59b4cfc412d8', '61aea55e97ad59b4cfc412da', '61aea55e97ad59b4cfc412df', '61aea55e97ad59b4cfc412e6', '61aea55e97ad59b4cfc412ea', '61aea55e97ad59b4cfc412ec', '61aea55e97ad59b4cfc412ee', '61aea55e97ad59b4cfc412f0', '61aea55e97ad59b4cfc412f3', '61aea55e97ad59b4cfc412fb', '61aea55e97ad59b4cfc412ff', '61aea55f97ad59b4cfc41301', '61aea55f97ad59b4cfc41304', '61aea55f97ad59b4cfc41306', '61aea55f97ad59b4cfc41307', '61aea55f97ad59b4cfc4130b', '61aea55f97ad59b4cfc4130c', '61aea55f97ad59b4cfc41318', '61aea55f97ad59b4cfc41319', '61aea55f97ad59b4cfc4131a', '61aea55f97ad59b4cfc4131d', '61aea55f97ad59b4cfc41320', '61aea55f97ad59b4cfc41330', '61aea55f97ad59b4cfc41331', '61aea55f97ad59b4cfc41332', '61aea55f97ad59b4cfc41334', '61aea55f97ad59b4cfc4133b', '61aea55f97ad59b4cfc4133c', '61aea56f97ad59b4cfc41342', '61aea56f97ad59b4cfc41344', '61aea56f97ad59b4cfc41347', '61aea56f97ad59b4cfc41349', '61aea56f97ad59b4cfc4134b', '61aea56f97ad59b4cfc4134c', '61aea56f97ad59b4cfc4134d', '61aea57097ad59b4cfc41351', '61aea57097ad59b4cfc41352', '61aea57097ad59b4cfc4135a', '61aea57097ad59b4cfc4135b', '61aea57097ad59b4cfc4135e', '61aea57097ad59b4cfc41361', '61aea57097ad59b4cfc41364', '61aea57097ad59b4cfc41365', '61aea57097ad59b4cfc41366', '61aea57097ad59b4cfc41367', '61aea57097ad59b4cfc41369', '61aea57197ad59b4cfc4136b', '61aea57197ad59b4cfc4136e', '61aea57197ad59b4cfc41372', '61aea57197ad59b4cfc41375', '61aea57197ad59b4cfc41376', '61aea57197ad59b4cfc41377', '61aea57197ad59b4cfc4137a', '61aea57297ad59b4cfc4137f', '61aea57297ad59b4cfc41380', '61aea57297ad59b4cfc41381', '61aea57297ad59b4cfc41382', '61aea57397ad59b4cfc41383', '61aea57397ad59b4cfc4138e', '61aea57397ad59b4cfc4138f', '61aea57397ad59b4cfc41391', '61aea57397ad59b4cfc41395', '61aea57397ad59b4cfc41399', '61aea57397ad59b4cfc4139a', '61aea57397ad59b4cfc4139c', '61aea57397ad59b4cfc4139e', '61aea57397ad59b4cfc413a7', '61aea57497ad59b4cfc413ad', '61aea57497ad59b4cfc413af', '61aea57497ad59b4cfc413b2', '61aea57497ad59b4cfc413b6', '61aea57497ad59b4cfc413be', '61aea57497ad59b4cfc413bd', '61aea57497ad59b4cfc413c0', '61aea57497ad59b4cfc413c4', '61aea57497ad59b4cfc413c9', '61aea57497ad59b4cfc413cc', '61aea57497ad59b4cfc413e0', '61aea57497ad59b4cfc413e1', '61aea57497ad59b4cfc413e3', '61aea57497ad59b4cfc413ea', '61aea57497ad59b4cfc413e7', '61aea57497ad59b4cfc413e8', '61aea57497ad59b4cfc413e9', '61aea57497ad59b4cfc413f1']\n",
      "IDs of the dev set are : ['61aea55f97ad59b4cfc41308', '61aea55d97ad59b4cfc412be', '61aea55c97ad59b4cfc412ac', '61aea55e97ad59b4cfc412fd', '61aea55f97ad59b4cfc41335', '61aea55c97ad59b4cfc412ae', '61aea55f97ad59b4cfc41336', '61aea57497ad59b4cfc413d1', '61aea57097ad59b4cfc41355', '61aea57397ad59b4cfc41393', '61aea57497ad59b4cfc413d7', '61aea57097ad59b4cfc41360', '61aea57097ad59b4cfc41368', '61aea56f97ad59b4cfc41343']\n",
      "IDs of the test set are : ['61aea55e97ad59b4cfc412de', '61aea55e97ad59b4cfc412eb', '61aea55f97ad59b4cfc41328', '61aea55f97ad59b4cfc4130e', '61aea55f97ad59b4cfc41323', '61aea55f97ad59b4cfc41337', '61aea55f97ad59b4cfc41322', '61aea57497ad59b4cfc413b3', '61aea57497ad59b4cfc413da', '61aea57497ad59b4cfc413d8', '61aea57497ad59b4cfc413d2', '61aea57497ad59b4cfc413ba', '61aea57097ad59b4cfc41358', '61aea57397ad59b4cfc413a5']\n"
     ]
    }
   ],
   "source": [
    "training_set = ['61aea55c97ad59b4cfc41290', '61aea55c97ad59b4cfc41297', '61aea55c97ad59b4cfc41299', '61aea55c97ad59b4cfc4129b', '61aea55c97ad59b4cfc4129d', '61aea55c97ad59b4cfc4129e', '61aea55c97ad59b4cfc4129f', '61aea55c97ad59b4cfc412a0', '61aea55c97ad59b4cfc412a1', '61aea55c97ad59b4cfc412a3', '61aea55c97ad59b4cfc412a4', '61aea55c97ad59b4cfc412a6', '61aea55c97ad59b4cfc412aa', '61aea55c97ad59b4cfc412af', '61aea55d97ad59b4cfc412b5', '61aea55d97ad59b4cfc412b7', '61aea55d97ad59b4cfc412bc', '61aea55d97ad59b4cfc412bd', '61aea55d97ad59b4cfc412bf', '61aea55d97ad59b4cfc412c1', '61aea55d97ad59b4cfc412c7', '61aea55d97ad59b4cfc412cb', '61aea55d97ad59b4cfc412cd', '61aea55d97ad59b4cfc412d2', '61aea55d97ad59b4cfc412d3', '61aea55e97ad59b4cfc412d4', '61aea55e97ad59b4cfc412d5', '61aea55e97ad59b4cfc412d7', '61aea55e97ad59b4cfc412d8', '61aea55e97ad59b4cfc412da', '61aea55e97ad59b4cfc412df', '61aea55e97ad59b4cfc412e6', '61aea55e97ad59b4cfc412ea', '61aea55e97ad59b4cfc412ec', '61aea55e97ad59b4cfc412ee', '61aea55e97ad59b4cfc412f0', '61aea55e97ad59b4cfc412f3', '61aea55e97ad59b4cfc412fb', '61aea55e97ad59b4cfc412ff', '61aea55f97ad59b4cfc41301', '61aea55f97ad59b4cfc41304', '61aea55f97ad59b4cfc41306', '61aea55f97ad59b4cfc41307', '61aea55f97ad59b4cfc4130b', '61aea55f97ad59b4cfc4130c', '61aea55f97ad59b4cfc41318', '61aea55f97ad59b4cfc41319', '61aea55f97ad59b4cfc4131a', '61aea55f97ad59b4cfc4131d', '61aea55f97ad59b4cfc41320', '61aea55f97ad59b4cfc41330', '61aea55f97ad59b4cfc41331', '61aea55f97ad59b4cfc41332', '61aea55f97ad59b4cfc41334', '61aea55f97ad59b4cfc4133b', '61aea55f97ad59b4cfc4133c', '61aea56f97ad59b4cfc41342', '61aea56f97ad59b4cfc41344', '61aea56f97ad59b4cfc41347', '61aea56f97ad59b4cfc41349', '61aea56f97ad59b4cfc4134b', '61aea56f97ad59b4cfc4134c', '61aea56f97ad59b4cfc4134d', '61aea57097ad59b4cfc41351', '61aea57097ad59b4cfc41352', '61aea57097ad59b4cfc4135a', '61aea57097ad59b4cfc4135b', '61aea57097ad59b4cfc4135e', '61aea57097ad59b4cfc41361', '61aea57097ad59b4cfc41364', '61aea57097ad59b4cfc41365', '61aea57097ad59b4cfc41366', '61aea57097ad59b4cfc41367', '61aea57097ad59b4cfc41369', '61aea57197ad59b4cfc4136b', '61aea57197ad59b4cfc4136e', '61aea57197ad59b4cfc41372', '61aea57197ad59b4cfc41375', '61aea57197ad59b4cfc41376', '61aea57197ad59b4cfc41377', '61aea57197ad59b4cfc4137a', '61aea57297ad59b4cfc4137f', '61aea57297ad59b4cfc41380', '61aea57297ad59b4cfc41381', '61aea57297ad59b4cfc41382', '61aea57397ad59b4cfc41383', '61aea57397ad59b4cfc4138e', '61aea57397ad59b4cfc4138f', '61aea57397ad59b4cfc41391', '61aea57397ad59b4cfc41395', '61aea57397ad59b4cfc41399', '61aea57397ad59b4cfc4139a', '61aea57397ad59b4cfc4139c', '61aea57397ad59b4cfc4139e', '61aea57397ad59b4cfc413a7', '61aea57497ad59b4cfc413ad', '61aea57497ad59b4cfc413af', '61aea57497ad59b4cfc413b2', '61aea57497ad59b4cfc413b6', '61aea57497ad59b4cfc413be', '61aea57497ad59b4cfc413bd', '61aea57497ad59b4cfc413c0', '61aea57497ad59b4cfc413c4', '61aea57497ad59b4cfc413c9', '61aea57497ad59b4cfc413cc', '61aea57497ad59b4cfc413e0', '61aea57497ad59b4cfc413e1', '61aea57497ad59b4cfc413e3', '61aea57497ad59b4cfc413ea', '61aea57497ad59b4cfc413e7', '61aea57497ad59b4cfc413e8', '61aea57497ad59b4cfc413e9', '61aea57497ad59b4cfc413f1']\n",
    "dev_set = ['61aea55f97ad59b4cfc41308', '61aea55d97ad59b4cfc412be', '61aea55c97ad59b4cfc412ac', '61aea55e97ad59b4cfc412fd', '61aea55f97ad59b4cfc41335', '61aea55c97ad59b4cfc412ae', '61aea55f97ad59b4cfc41336', '61aea57497ad59b4cfc413d1', '61aea57097ad59b4cfc41355', '61aea57397ad59b4cfc41393', '61aea57497ad59b4cfc413d7', '61aea57097ad59b4cfc41360', '61aea57097ad59b4cfc41368', '61aea56f97ad59b4cfc41343']\n",
    "test_set = ['61aea55e97ad59b4cfc412de', '61aea55e97ad59b4cfc412eb', '61aea55f97ad59b4cfc41328', '61aea55f97ad59b4cfc4130e', '61aea55f97ad59b4cfc41323', '61aea55f97ad59b4cfc41337', '61aea55f97ad59b4cfc41322', '61aea57497ad59b4cfc413b3', '61aea57497ad59b4cfc413da', '61aea57497ad59b4cfc413d8', '61aea57497ad59b4cfc413d2', '61aea57497ad59b4cfc413ba', '61aea57097ad59b4cfc41358', '61aea57397ad59b4cfc413a5']\n",
    "\n",
    "print(f'IDs of the training set are : {training_set}')\n",
    "print(f'IDs of the dev set are : {dev_set}')\n",
    "print(f'IDs of the test set are : {test_set}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004089bd",
   "metadata": {},
   "source": [
    "# Phase 2 - Deciding on a Sentence Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2575350",
   "metadata": {},
   "source": [
    "#### Creation of the corpus\n",
    "\n",
    "Credit for code goes to M. Grabmair and his LDSI_W21_Classifier_Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70f0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all sentences assuming every annotation is a sentence\n",
    "def make_span_data(documents_by_id, types_by_id, annotations):\n",
    "    span_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents_by_id[a['document']]['plainText']\n",
    "        atype = a['type']\n",
    "        sd = {'txt': document_txt[start:end],\n",
    "              'document': a['document'],\n",
    "              'type': types_by_id[atype]['name'],\n",
    "              'start': a['start'],\n",
    "              'start_normalized': a['start'] / len(document_txt), #normalized position\n",
    "              'end': a['end']}\n",
    "        span_data.append(sd)\n",
    "    return span_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502544a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15349\n"
     ]
    }
   ],
   "source": [
    "spans = make_span_data(documents_by_id, types_by_id, annotations) # dictionary\n",
    "span_labels = [s['type'] for s in spans] #e.g. \"Citation\", \"CaseFooter\", \"Header\", etc.\n",
    "print(len(spans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd13fdd",
   "metadata": {},
   "source": [
    "### 2.1 Standard segmentation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1b4ea",
   "metadata": {},
   "source": [
    "#### Individual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d114879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'txt': \"____________________________________________\\r\\nDEBORAH W. SINGLETON\\r\\nVeterans Law Judge, Board of Veterans' Appeals\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n Department of Veterans Affairs\\r\", 'document': '61aea57397ad59b4cfc41399', 'type': 'CaseFooter', 'start': 15922, 'start_normalized': 0.9899894298327426, 'end': 16078}\n"
     ]
    }
   ],
   "source": [
    "#Print the first span to know its structure\n",
    "print(spans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b272ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training set 113\n",
      "ID of the [0](st.|rd.|th.)element in the document. Doc in the training_set with id [61aea55c97ad59b4cfc41290] with keys [dict_keys(['_id', 'name', 'plainText', 'outcome'])]\n",
      "****************************************************************************************************\n",
      "The document has the following information:\n",
      "\t===>ID 61aea55c97ad59b4cfc41290\n",
      "\t===>Name 0619915.txt\n",
      "\t===>PlainText[0:50] Citation Nr: 0619915\t\r\n",
      "Decision Date: 07/10/06    Archive Date: 07/21/06\r\n",
      "\r\n",
      "DOCKET NO.  03-37 139\t)\t\n",
      "\t===>Outcome granted\n"
     ]
    }
   ],
   "source": [
    "# Print length of the training set\n",
    "print(f'Length training set {len(training_set)}')\n",
    "\n",
    "# Get ID of a document from the training_set\n",
    "index_doc_stdSeg = 0\n",
    "id_doc_stdSeg = training_set[index_doc_stdSeg]\n",
    "doc_std_seg = documents_by_id.get(training_set[index_doc_stdSeg])\n",
    "print(f'ID of the [{index_doc_stdSeg}](st.|rd.|th.)element in the document. Doc in the training_set with id [{id_doc_stdSeg}] with keys [{doc_std_seg.keys()}]')\n",
    "print(\"*\"*100)\n",
    "print(f'The document has the following information:\\n\\t===>ID {doc_std_seg.get(\"_id\")}\\n\\t===>Name {doc_std_seg.get(\"name\")}\\n\\t===>PlainText[0:50] {doc_std_seg.get(\"plainText\")[0:100]}\\n\\t===>Outcome {doc_std_seg.get(\"outcome\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1e5027",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#spacy.prefer_gpu()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/util.py:427\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "#spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605505dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docSpacy_stdSegIndiv = nlp(doc_std_seg.get(\"plainText\"))\n",
    "print(docSpacy_stdSegIndiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities\n",
    "#docSpacy_stdSegIndiv.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283df65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sentences and printing how many this document has\n",
    "sents_std_seg_ind = [str(obj) for obj in docSpacy_stdSegIndiv.sents]\n",
    "print(len(sents_std_seg_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d33de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentence in docSpacy_stdSegIndiv.sents:\n",
    "    print(sentence.text)\n",
    "    print(\"%\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73032d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_per_document = { \"_id\": id_doc_stdSeg, \"spans\": [] }\n",
    "\n",
    "spans_per_document[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == id_doc_stdSeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in spans_per_document[\"spans\"]: \n",
    "    print(sentence[\"txt\"])\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1767a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetricsNewApproach(annotations, predictions, document):\n",
    "    listMatchedTrueSplits = []\n",
    "    truePositives = 0\n",
    "    trueNegatives = 0\n",
    "    falsePositives = 0\n",
    "    falseNegatives = 0\n",
    "    interval = 3\n",
    "    \n",
    "    for p in predictions:\n",
    "        indexPred = document.index(p)\n",
    "        flagMatched = False\n",
    "        \n",
    "        for i,a in enumerate(annotations):\n",
    "            if a[\"start\"]-interval <= indexPred and indexPred <= a[\"start\"]+interval:\n",
    "                truePositives += 1\n",
    "                flagMatched = True\n",
    "                listMatchedTrueSplits.append(i)\n",
    "                break\n",
    "        if not flagMatched:\n",
    "            falsePositives += 1\n",
    "            \n",
    "    listMatchedTrueSplits.sort()\n",
    "    listMatchedTrueSplits = list(dict.fromkeys(listMatchedTrueSplits))\n",
    "    listMissing = [x for x in range(0, len(annotations)) if x not in listMatchedTrueSplits]\n",
    "    falseNegatives=len(listMissing)\n",
    "    \n",
    "    accuracy = (truePositives+trueNegatives)/(truePositives+falsePositives+falseNegatives+trueNegatives)\n",
    "    precision = truePositives/(truePositives+falsePositives)\n",
    "    recall = truePositives/(truePositives+falseNegatives)\n",
    "    f1Score = 2*(recall * precision) / (recall + precision)\n",
    "    \n",
    "    return accuracy, precision, recall, f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e17550",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_std_seg_ind = [str(obj) for obj in docSpacy_stdSegIndiv.sents]\n",
    "\n",
    "computeMetricsNewApproach(copy.copy(spans_per_document[\"spans\"]), copy.copy(sentences_std_seg_ind), copy.copy(doc_std_seg.get(\"plainText\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f12e2",
   "metadata": {},
   "source": [
    "#### Collective analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1Score = 0\n",
    "\n",
    "for id_doc in training_set:\n",
    "    doc_by_id = documents_by_id.get(id_doc)\n",
    "    \n",
    "    #DocSpacy is obtained\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    docSpacy = nlp(doc_by_id.get(\"plainText\"))\n",
    "    \n",
    "    #Sentences\n",
    "    sentences = [str(obj) for obj in docSpacy.sents]\n",
    "    \n",
    "    #Spans of the document are obtained\n",
    "    spans_per_document = { \"_id\": id_doc, \"spans\": [] }\n",
    "    spans_per_document[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == id_doc]\n",
    "    \n",
    "    result = computeMetricsNewApproach(copy.deepcopy(spans_per_document[\"spans\"]), copy.copy(sentences), copy.deepcopy(doc_by_id.get(\"plainText\")))\n",
    "    \n",
    "    accuracy += result[0]\n",
    "    precision += result[1]\n",
    "    recall += result[2]\n",
    "    f1Score += result[3]\n",
    "    \n",
    "accuracy /= len(training_set)\n",
    "precision /= len(training_set)\n",
    "recall /= len(training_set)\n",
    "f1Score /= len(training_set)\n",
    "\n",
    "print(f'accuracy {accuracy}, precision {precision}, recall {recall}, f1Score {f1Score}')\n",
    "\n",
    "#accuracy 0.4220689794749151, precision 0.5876022051703683, recall 0.5954441815125752, f1Score 0.5900457535737149"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f01c7",
   "metadata": {},
   "source": [
    "### 2.2 Improved segmentation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new rule to the pipeline. In this case numbered list\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer.add_special_case('1.', [{ORTH: '1.'}])\n",
    "nlp.tokenizer.add_special_case('2.', [{ORTH: '2.'}])\n",
    "nlp.tokenizer.add_special_case('3.', [{ORTH: '3.'}])\n",
    "nlp.tokenizer.add_special_case('a.', [{ORTH: 'a.'}])\n",
    "nlp.tokenizer.add_special_case('b.', [{ORTH: 'b.'}])\n",
    "nlp.tokenizer.add_special_case('c.', [{ORTH: 'c.'}])\n",
    "nlp.tokenizer.add_special_case('I.', [{ORTH: 'I.'}])\n",
    "nlp.tokenizer.add_special_case('II.', [{ORTH: 'II.'}])\n",
    "nlp.tokenizer.add_special_case('III.', [{ORTH: 'III.'}])\n",
    "nlp.tokenizer.add_special_case('REPRESENTATION', [{ORTH: 'REPRESENTATION'}])\n",
    "nlp.tokenizer.add_special_case('THE ISSUE', [{ORTH: 'THE ISSUE'}])\n",
    "nlp.tokenizer.add_special_case('ATTORNEY FOR THE BOARD', [{ORTH: 'ATTORNEY FOR THE BOARD'}])\n",
    "nlp.tokenizer.add_special_case('ORDER', [{ORTH: 'ORDER'}])\n",
    "nlp.tokenizer.add_special_case('FINDINGS OF FACT', [{ORTH: 'FINDINGS OF FACT'}])\n",
    "nlp.tokenizer.add_special_case('CONCLUSION OF LAW', [{ORTH: 'CONCLUSION OF LAW'}])\n",
    "nlp.tokenizer.add_special_case('INTRODUCTION', [{ORTH: 'INTRODUCTION'}])\n",
    "nlp.tokenizer.add_special_case('WITNESS AT HEARINGS ON APPEAL', [{ORTH: 'WITNESS AT HEARINGS ON APPEAL'}])\n",
    "nlp.tokenizer.add_special_case('REASONS AND BASES FOR FINDINGS AND CONCLUSION', [{ORTH: 'REASONS AND BASES FOR FINDINGS AND CONCLUSION'}])\n",
    "regexBoundaryDigits = re.compile('^[0-9]$')\n",
    "\n",
    "@Language.component(\"my_component\")\n",
    "def custom_headers(doc):\n",
    "    flagNext = False\n",
    "    listHeaders = [\"REPRESENTATION\", \"THE ISSUE\", \"ATTORNEY FOR THE BOARD\", \"ORDER\", \"FINDINGS OF FACT\", \"CONCLUSION OF LAW\", \"INTRODUCTION\", \"WITNESS AT HEARING ON APPEAL\", \"FINDING OF FACT\", \"REASONS AND BASES FOR FINDING AND CONCLUSION\"]\n",
    "    for index, token in enumerate(doc):\n",
    "        if flagNext and not token.text:\n",
    "            token.sent_start = True\n",
    "            flagNext = False\n",
    "        \n",
    "        if token.text in listHeaders:\n",
    "            token.sent_start = True\n",
    "            flagNext = True\n",
    "    return doc\n",
    "\n",
    "Language.component(\"custom_headers\", func=custom_headers)\n",
    "\n",
    "nlp.add_pipe(\"custom_headers\", before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1Score = 0\n",
    "\n",
    "for id_doc in training_set:\n",
    "    doc_by_id = documents_by_id.get(id_doc)\n",
    "    \n",
    "    #DocSpacy is obtained    \n",
    "    docSpacy = nlp(doc_by_id.get(\"plainText\"))\n",
    "    \n",
    "    #Sentences\n",
    "    sentences = [str(obj) for obj in docSpacy.sents]\n",
    "    \n",
    "    #Spans of the document are obtained\n",
    "    spans_per_document = { \"_id\": id_doc, \"spans\": [] }\n",
    "    spans_per_document[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == id_doc]\n",
    "    \n",
    "    result = computeMetricsNewApproach(copy.deepcopy(spans_per_document[\"spans\"]), copy.copy(sentences), copy.deepcopy(doc_by_id.get(\"plainText\")))\n",
    "    \n",
    "    accuracy += result[0]\n",
    "    precision += result[1]\n",
    "    recall += result[2]\n",
    "    f1Score += result[3]\n",
    "\n",
    "accuracy /= len(training_set)\n",
    "precision /= len(training_set)\n",
    "recall /= len(training_set)\n",
    "f1Score /= len(training_set)\n",
    "\n",
    "print(f'accuracy {accuracy}, precision {precision}, recall {recall}, f1Score {f1Score}')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ddc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_doc_stdSeg = 0\n",
    "id_doc_stdSeg = training_set[index_doc_stdSeg]\n",
    "doc_std_seg = documents_by_id.get(training_set[index_doc_stdSeg])\n",
    "\n",
    "docSpacy_stdSegIndiv = nlp(doc_std_seg.get(\"plainText\"))\n",
    "\n",
    "for sentence in docSpacy_stdSegIndiv.sents:\n",
    "    print(sentence.text)\n",
    "    print(\"%\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1Score = 0\n",
    "\n",
    "for id_doc in training_set:\n",
    "    doc_by_id = documents_by_id.get(id_doc)\n",
    "    \n",
    "    #DocSpacy is obtained    \n",
    "    docSpacy = nlp(doc_by_id.get(\"plainText\"))\n",
    "    \n",
    "    #Sentences\n",
    "    sentences = [str(obj) for obj in docSpacy.sents]\n",
    "    \n",
    "    #Spans of the document are obtained\n",
    "    spans_per_document = { \"_id\": id_doc, \"spans\": [] }\n",
    "    spans_per_document[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == id_doc]\n",
    "    \n",
    "    result = computeMetricsNewApproach(copy.deepcopy(spans_per_document[\"spans\"]), copy.copy(sentences), copy.deepcopy(doc_by_id.get(\"plainText\")))\n",
    "    \n",
    "    accuracy += result[0]\n",
    "    precision += result[1]\n",
    "    recall += result[2]\n",
    "    f1Score += result[3]\n",
    "\n",
    "accuracy /= len(training_set)\n",
    "precision /= len(training_set)\n",
    "recall /= len(training_set)\n",
    "f1Score /= len(training_set)\n",
    "\n",
    "\n",
    "print(f'accuracy {accuracy}, precision {precision}, recall {recall}, f1Score {f1Score}')\n",
    "#accuracy 0.45684867111110933, precision 0.5956175404449385, recall 0.6583961801916716, f1Score 0.6246184746083606\n",
    "#### With interval of 5\n",
    "#accuracy 0.6967265369532635, precision 0.7822844028944752, recall 0.8626031173254878, f1Score 0.8193964537620934\n",
    "#### With interval of 6\n",
    "#accuracy 0.740566313643408, precision 0.8211516129093976, recall 0.883276911756848, f1Score 0.8497883236613925"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0c05d",
   "metadata": {},
   "source": [
    "### 2.3 Law-specific sentence segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5180f",
   "metadata": {},
   "source": [
    "#### Individual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb790d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docLawSpec_0 = documents_by_id.get(training_set[0]).get(\"plainText\")\n",
    "print(docLawSpec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45218d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentLegalSegmenter = [sent for sent in sbd_utils.text2sentences(docLawSpec_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sentLegalSegmenter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b16942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentLegalSegmenter: print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf20768",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_per_document = { \"_id\": training_set[0], \"spans\": [] }\n",
    "\n",
    "spans_per_document[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == training_set[0]]\n",
    "\n",
    "len(spans_per_document[\"spans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetricsLegalSpecific(annotations, predictions, document):\n",
    "    listMatchedTrueSplits = []\n",
    "    truePositives = 0\n",
    "    trueNegatives = 0\n",
    "    falsePositives = 0\n",
    "    falseNegatives = 0\n",
    "    interval = 3\n",
    "    \n",
    "    for p in predictions:\n",
    "        indexPred = document.index(p)\n",
    "        flagMatched = False\n",
    "        \n",
    "        for i,a in enumerate(annotations):\n",
    "            if a[\"start\"]-interval <= indexPred and indexPred <= a[\"start\"]+interval:\n",
    "                truePositives += 1\n",
    "                flagMatched = True\n",
    "                listMatchedTrueSplits.append(i)\n",
    "                break\n",
    "        if not flagMatched:\n",
    "            falsePositives += 1\n",
    "            \n",
    "    listMatchedTrueSplits.sort()\n",
    "    listMatchedTrueSplits = list(dict.fromkeys(listMatchedTrueSplits))\n",
    "    listMissing = [x for x in range(0, len(annotations)) if x not in listMatchedTrueSplits]\n",
    "    falseNegatives=len(listMissing)\n",
    "    \n",
    "    accuracy = (truePositives+trueNegatives)/(truePositives+falsePositives+falseNegatives+trueNegatives)\n",
    "    precision = truePositives/(truePositives+falsePositives)\n",
    "    recall = truePositives/(truePositives+falseNegatives)\n",
    "    f1Score = 2*(recall * precision) / (recall + precision)\n",
    "    \n",
    "    return accuracy, precision, recall, f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1Score = computeMetricsLegalSpecific(copy.deepcopy(spans_per_document[\"spans\"]), copy.copy(sentLegalSegmenter), docLawSpec_0)\n",
    "\n",
    "print(f'accuracy {accuracy}, precision {precision}, recall {recall}, f1Score {f1Score}')\n",
    "\"\"\"\n",
    "TruePositives 109 - TrueNegatives 0 - falsePositives 15 - falseNegatives 3\n",
    "accuracy 0.8582677165354331, precision 0.8790322580645161, recall 0.9732142857142857, f1Score 0.923728813559322\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d721b",
   "metadata": {},
   "source": [
    "#### Collective analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1Score = 0\n",
    "\n",
    "for id_doc in training_set:\n",
    "    doc_by_id = documents_by_id.get(id_doc)\n",
    "    \n",
    "    #Sentences\n",
    "    sentences = [sent for sent in sbd_utils.text2sentences(doc_by_id.get(\"plainText\"))]\n",
    "    \n",
    "    #Spans of the document are obtained\n",
    "    spans_per_document = { \"_id\": id_doc, \"spans\": [] }\n",
    "    spans_per_document[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == id_doc]\n",
    "    \n",
    "    result = computeMetricsLegalSpecific(copy.deepcopy(spans_per_document[\"spans\"]), copy.copy(sentences), doc_by_id.get(\"plainText\"))\n",
    "    \n",
    "    accuracy += result[0]\n",
    "    precision += result[1]\n",
    "    recall += result[2]\n",
    "    f1Score += result[3]\n",
    "\n",
    "accuracy /= len(training_set)\n",
    "precision /= len(training_set)\n",
    "recall /= len(training_set)\n",
    "f1Score /= len(training_set)\n",
    "\n",
    "\n",
    "print(f'accuracy {accuracy}, precision {precision}, recall {recall}, f1Score {f1Score}')\n",
    "#accuracy 0.8138229150722465, precision 0.8324095133044638, recall 0.9716983081350014, f1Score 0.8931354492101693"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37940562",
   "metadata": {},
   "source": [
    "# Phase 3 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_files_unlabeled = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "print(f'Num files {len(name_files_unlabeled)} in {os.path.join(project_config.UNLABELED_DIR)} directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258b4ea",
   "metadata": {},
   "source": [
    "### 3.1 Splitting unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Change to file\n",
    "def getSententesWithSegmenterPerFile(filename):\n",
    "    print(filename, end = '')\n",
    "    path_file = os.path.join(project_config.UNLABELED_DIR, filename)\n",
    "    #print(f'{mp.current_process()} - {filename} - {path_file}\\n')    \n",
    "    try:         \n",
    "        raw = open(path_file, 'rb').read()\n",
    "        enc = chardet.detect(raw)['encoding']\n",
    "        #with codecs.open(path_file, mode='r', encoding=enc) as f:\n",
    "        with open(path_file, encoding='latin-1') as f:\n",
    "            return len(sbd_utils.text2sentences(f.read()))\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        return 0\n",
    "    \n",
    "    return 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "list_files_x_names = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "print(f'list_files_x_names length = {len(list_files_x_names)}')\n",
    "num_sentences_x_file = pool.map(sentences_custom.getLengthSententesWithSegmenterPerFile, list_files_x_names)\n",
    "print(\"\")\n",
    "print(\"The sum of num_sentences_x_file is\", sum(num_sentences_x_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8483559",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files_x_names = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "list_files_x_names = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "print(f'list_files_x_names length = {len(list_files_x_names)}')\n",
    "list_files_name_num_sents = pool.map(sentences_custom.getSententesWithSegmenterPerFile, list_files_x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files_name_num_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc647925",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_files_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b939c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean every variable (Point 3 up to here)\n",
    "\n",
    "del name_files_unlabeled\n",
    "del list_files_x_names\n",
    "del num_sentences_x_file\n",
    "del list_files_name_num_sents\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74cf41",
   "metadata": {},
   "source": [
    "##### Storing \"list_files_x_names\" and  \"num_sentences_x_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file\n",
    "file = open(\"ListFiles.txt\", \"w\")\n",
    " \n",
    "#convert variable to string\n",
    "str = repr(list_files_x_names)\n",
    "file.write(\"list_files_x_names = \" + str + \"\\n\")\n",
    " \n",
    "#close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file\n",
    "file = open(\"ListNumSentencesXfile.txt\", \"w\")\n",
    " \n",
    "#convert variable to string\n",
    "str = repr(num_sentences_x_file)\n",
    "file.write(\"num_sentences_x_file = \" + str + \"\\n\")\n",
    " \n",
    "#close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb99a34",
   "metadata": {},
   "source": [
    "##### Reading \"list_files_x_names\" and  \"num_sentences_x_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ListFiles.txt', 'rb') as f:\n",
    "    list_files_x_names = f.read()\n",
    "    f.close()\n",
    "    \n",
    "singleStrWithNames = (str(list_files_x_names)).split(\"=\")[1].strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "list_files_x_names = [name.replace(\"'\", \"\").strip() for name in singleStrWithNames.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ListNumSentencesXfile.txt', 'rb') as f:\n",
    "    num_sentences_x_file = f.read()\n",
    "    f.close()\n",
    "\n",
    "singleStrWithIndex = (str(num_sentences_x_file)).split(\"=\")[1].strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "num_sentences_x_file = [int(re.sub(r'\\D', '', name)) for name in singleStrWithIndex.split(\",\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c64320",
   "metadata": {},
   "source": [
    "### 3.2 Sentence-wise preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768da7ff",
   "metadata": {},
   "source": [
    "Credit for the code goes to M. Grabmair and his LDSI_W21_Classifier_Workshop. It has been applied a small change in the tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    txt = txt.replace(\"_\", \"\")\n",
    "    dirty_tokens = re.split('\\s+', txt)  # split words.\n",
    "    print(f'dirty_tokens {dirty_tokens}')\n",
    "    # remove all non-alphanumerics\n",
    "    clean_tokens = [re.sub(r'\\W', '', t).lower() for t in dirty_tokens]\n",
    "    clean_tokens = [t for t in clean_tokens if t] # Remove empty strings  <<===============\n",
    "    return clean_tokens\n",
    "\n",
    "def tokenize_spans(spans):\n",
    "    for s in spans:\n",
    "        s['tokens_manual'] = tokenize(s['txt'])        \n",
    "        \n",
    "def build_vocabulary(spans): #A dictionary of how often a word appears\n",
    "    vocab_counts = {}\n",
    "    for sd in spans:\n",
    "        for t in tokenize(sd['txt']):\n",
    "            if t in vocab_counts:\n",
    "                vocab_counts[t] += 1\n",
    "            else:\n",
    "                vocab_counts[t] = 1\n",
    "    return vocab_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_doc_in_json_list = 0\n",
    "id_doc_tokenizer_example = training_set[index_doc_in_json_list]\n",
    "doc_tokenizer_example = documents_by_id.get(training_set[index_doc_in_json_list])\n",
    "\n",
    "spans_per_document_tokenizer = { \"_id\": id_doc_tokenizer_example, \"spans\": [] }\n",
    "\n",
    "spans_per_document_tokenizer[\"spans\"] = [doc for doc in spans if doc.get(\"document\") == id_doc_tokenizer_example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27285680",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_span_in_document = 11\n",
    "spans_per_document_tokenizer[\"spans\"][id_span_in_document][\"txt\"]\n",
    "#len(spans_per_document_tokenizer[\"spans\"])-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fda352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(spans_per_document_tokenizer[\"spans\"][id_span_in_document][\"txt\"]) #Tokenize with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexSpan = 10\n",
    "auxSpan = spans_per_document_tokenizer[\"spans\"][indexSpan][\"txt\"]\n",
    "print(auxSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "list_files_x_names = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "print(f'list_files_x_names length = {len(list_files_x_names)}')\n",
    "list_files_name_num_sents = pool.map(sentences_custom.getSententesWithSegmenterPerFile, list_files_x_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3229be",
   "metadata": {},
   "source": [
    "#### Write list of dictionaries into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"FileListOfDictNameNumSentences.txt\", \"w\")\n",
    " \n",
    "#convert variable to string\n",
    "str_list_files_x_names = repr(list_files_name_num_sents)\n",
    "file.write(str_list_files_x_names + \"\\n\")\n",
    " \n",
    "#close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb57353",
   "metadata": {},
   "source": [
    "#### Read list of dictionaries from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e180b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import ast\n",
    "\n",
    "with open('FileListOfDictNameNumSentences.txt', 'rb') as f:\n",
    "    list_files_x_names = ast.literal_eval(f.read())\n",
    "    f.close()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "name_files_unlabeled = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "print(f'Num files {len(name_files_unlabeled)} in {os.path.join(project_config.UNLABELED_DIR)} directory')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3298826",
   "metadata": {},
   "source": [
    "### Normal execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "num_tokens_x_file = pool.map(sentences_custom.getNumTokensPerFile, list_files_name_num_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_tokens_x_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean every variable \n",
    "\n",
    "del num_tokens_x_file\n",
    "del pool\n",
    "del list_files_name_num_sents\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import glob\n",
    "\n",
    "files = glob.glob(os.path.join(project_config.OUTPUT_DIR, \"*\"))\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156cea31",
   "metadata": {},
   "source": [
    "#### Test after fail due to special character in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc249168",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_files_unlabeled = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "list_files_x_names_tokens = os.listdir(os.path.join(project_config.OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_files_x_names_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d86bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_missing_files = [file for file in name_files_unlabeled if (\"o_\"+file) not in list_files_x_names_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbdfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ffae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info from files (name, length, sentences)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "print(f'list_files_x_names length = {len(list_missing_files)}')\n",
    "list_files_name_num_sents = pool.map(sentences_custom.getSententesWithSegmenterPerFile, list_missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_files_name_num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158aa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens and produce files\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "num_tokens_x_file = pool.map(sentences_custom.getNumTokensPerFile, list_files_name_num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b32c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_x_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ee14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del list_files_x_names_tokens\n",
    "del list_missing_files\n",
    "del pool\n",
    "del list_files_name_num_sents\n",
    "del num_tokens_x_file\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f81a4",
   "metadata": {},
   "source": [
    "### Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_tokens = os.path.join(project_config.FILENAME_OUTPUT_TOKENS)\n",
    "\n",
    "file_tokens = open(filename_tokens, \"w\")\n",
    "list_files = os.listdir(os.path.join(project_config.OUTPUT_DIR))\n",
    "print(len(list_files))\n",
    "\n",
    "for filename in list_files:\n",
    "    \n",
    "    with open(os.path.join(project_config.OUTPUT_DIR, filename), 'r') as f:\n",
    "        #Read from source\n",
    "        string_aux = f.readlines()\n",
    "        #Write to dest\n",
    "        for line in string_aux:\n",
    "            file_tokens.write(line)\n",
    "        \n",
    "        f.close()\n",
    "\n",
    "file_tokens.close()\n",
    "\n",
    "del filename_tokens\n",
    "del file_tokens\n",
    "del list_files\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b20b7",
   "metadata": {},
   "source": [
    "#### Count number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_tokens = os.path.join(project_config.FILENAME_OUTPUT_TOKENS)\n",
    "\n",
    "file = open(filename_tokens, \"rt\")\n",
    "data = file.read()\n",
    "words = data.split()\n",
    "\n",
    "print('Number of words in text file :', len(words))\n",
    "\n",
    "del filename_tokens\n",
    "del file\n",
    "del data\n",
    "del words\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e816e0",
   "metadata": {},
   "source": [
    "### Generate histogram tokens per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentences from files. As a result we have a list of dictionaries with keys: \"name\", \"num_sentences\", \"sentences\"\n",
    "list_files_x_names = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "list_files_x_names = os.listdir(os.path.join(project_config.UNLABELED_DIR))\n",
    "print(f'list_files_x_names length = {len(list_files_x_names)}')\n",
    "list_files_name_num_sents = pool.map(sentences_custom.getSententesWithSegmenterPerFile, list_files_x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_files_name_num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a320d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get num tokens per file\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "num_tokens_x_file = pool.map(sentences_custom.getListNumTokensPerFile, list_files_name_num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aee8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_tokens_x_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d960529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(num_tokens_x_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The document with most tokens has {max(num_tokens_x_file)}. ', end=\"\")\n",
    "index_max = num_tokens_x_file.index(max(num_tokens_x_file))\n",
    "print(f'It is located in the file {list_files_name_num_sents[index_max].get(\"name\")}')\n",
    "\n",
    "print(f'The document with least tokens has {min(num_tokens_x_file)}. ', end=\"\")\n",
    "index_min = num_tokens_x_file.index(min(num_tokens_x_file))\n",
    "print(f'It is located in the file {list_files_name_num_sents[index_min].get(\"name\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_tokens_x_file, bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e872c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files_name_num_sents[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write num_tokens_x_file\n",
    "\"\"\"\n",
    "file = open(\"FileNumTokensXFile.txt\", \"w\")\n",
    " \n",
    "#convert variable to string\n",
    "str_num_tokens_x_file = repr(num_tokens_x_file)\n",
    "file.write(str_num_tokens_x_file + \"\\n\")\n",
    " \n",
    "#close file\n",
    "file.close()\n",
    "\"\"\"\n",
    "# Write name files of num_tokens_x_file\n",
    "\"\"\"\n",
    "file = open(\"FileListFiles_x_numTokensXFile.txt\", \"w\")\n",
    " \n",
    "#convert variable to string\n",
    "str_list_namefiles_tokens = repr(list_files_x_names)\n",
    "file.write(str_list_namefiles_tokens + \"\\n\")\n",
    " \n",
    "#close file\n",
    "file.close()\n",
    "\n",
    "del file\n",
    "del str_list_namefiles_tokens\n",
    "del str_num_tokens_x_file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean every variable \n",
    "\n",
    "del num_tokens_x_file\n",
    "del pool\n",
    "del list_files_name_num_sents\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09054b",
   "metadata": {},
   "source": [
    "# Phase 4 - Developing word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff06fde",
   "metadata": {},
   "source": [
    "### 4.1 Custom FastText Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2653308",
   "metadata": {},
   "source": [
    "The following line was executed in the command line:\n",
    "\n",
    "> ./fasttext skipgram -input output_tokens.txt  -output model_ldsi_skipgram -verbose 2 -minCount 20 -dim 100 -epoch 10 -thread 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da149fc",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating Custom Embeddings Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234877b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_current_file = os.path.abspath('')\n",
    "print(f'path_current_file: {path_current_file}')\n",
    "pathModel = os.path.join(path_current_file, project_config.PATH_MODEL_FASTTEXT)\n",
    "print(f'pathModel: {pathModel}')\n",
    "modelFastText = fasttext.load_model(pathModel)#, model='skipgram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = modelFastText.get_words(on_unicode_error='ignore')#replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd9e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[20100:20200]\n",
    "modelFastText.get_word_vector(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = [\"veteran\", \"v.\", \"argues\", \"ptsd\", \"granted\", \"korea\", \"holding\", \"also\", \"diagnosed\", \"injure\", \"surgery\", \"spine\", \"accident\", \"disorder\", \"posttraumatic\", \"depression\", \"anxiety\"]\n",
    "\n",
    "for word_to_search in list_words:\n",
    "    print(word_to_search, \"*\"*60)\n",
    "    list_nn_of_word = modelFastText.get_nearest_neighbors(word_to_search)\n",
    "    for nn in list_nn_of_word:\n",
    "        print(\"\\t\", nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097423ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathModel\n",
    "del path_current_file\n",
    "del modelFastText \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114c2dd",
   "metadata": {},
   "source": [
    "# Phase 5 - Training Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518259c",
   "metadata": {},
   "source": [
    "abridged from [scikit-learn example code](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) and to M. Grabmair and his LDSI_W21_Classifier_Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0432e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee99d3a",
   "metadata": {},
   "source": [
    "Credit for code goes to [buhrmann.github.io](https://buhrmann.github.io/tfidf-analysis.html) and to M. Grabmair and his LDSI_W21_Classifier_Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_tfidf_features(row, features, top_n=15):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "\n",
    "def top_features_in_doc(Xtr, features, row_id, top_n=15):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    xtr_row = Xtr[row_id]\n",
    "    if type(xtr_row) is not np.ndarray:\n",
    "        xtr_row = xtr_row.toarray()\n",
    "    row = np.squeeze(xtr_row)\n",
    "    return top_tfidf_features(row, features, top_n)\n",
    "\n",
    "\n",
    "def top_mean_features(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids]\n",
    "    else:\n",
    "        D = Xtr\n",
    "    if type(D) is not np.ndarray:\n",
    "        D = D.toarray()\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_features(tfidf_means, features, top_n)\n",
    "\n",
    "\n",
    "def top_features_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = {}\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_features(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs[label] = feats_df\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def span_top_tfidf(spans_txt, spans_tfidf, features, index):\n",
    "    print('span text:\\n'+spans_txt[index]+'\\n')\n",
    "    print(top_features_in_doc(spans_tfidf, features, index))\n",
    "    \n",
    "#We can give it a look on the Github webpage posted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_errors(clf, eval_spans, vectorizer, \n",
    "                      select_true_label=None, \n",
    "                      select_pred_label=None):\n",
    "    eval_X, eval_y = make_feature_vectors_and_labels(eval_spans, vectorizer)\n",
    "    eval_spans_txt = [s['txt'] for s in eval_spans]\n",
    "    eval_spans_labels = [s['type'] for s in eval_spans]\n",
    "    pred_y = clf.predict(eval_X)\n",
    "    for i in range(len(eval_spans)):\n",
    "        true_label = eval_spans_labels[i]\n",
    "        pred_label = pred_y[i]\n",
    "        if true_label != pred_label:\n",
    "            if select_true_label and true_label != select_true_label: continue\n",
    "            if select_pred_label and pred_label != select_pred_label: continue\n",
    "            doc_name = documents_by_id[eval_spans[i]['document']]['name']\n",
    "            print('sentence # '+str(i)+' / case '+doc_name+' / @'+str(eval_spans[i]['start']))\n",
    "            print('pred: '+pred_label+' / true: '+true_label)\n",
    "            print(eval_spans[i]['txt'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a6c86",
   "metadata": {},
   "source": [
    "### 5.1 TFIDF featurization\n",
    "\n",
    "Credit for code goes to M. Grabmair and his LDSI_W21_Classifier_Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cb683",
   "metadata": {},
   "source": [
    "##### Creation of spans (training, dev & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spans = [span for span in spans if span[\"document\"] in training_set]\n",
    "dev_spans = [span for span in spans if span[\"document\"] in dev_set]\n",
    "test_spans = [span for span in spans if span[\"document\"] in test_set]\n",
    "\n",
    "print(f'Size of train_span is {len(train_spans)}')\n",
    "print(f'Size of dev_spans is {len(dev_spans)}')\n",
    "print(f'Size of test_spans is {len(test_spans)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b3426",
   "metadata": {},
   "source": [
    "##### Creation of spans_text (training, dev & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spans_txt = [span.get(\"txt\") for span in train_spans]\n",
    "dev_spans_txt = [span.get(\"txt\") for span in dev_spans]\n",
    "test_spans_txt = [span.get(\"txt\") for span in test_spans]\n",
    "\n",
    "print(f'Size of train_spans_txt is {len(train_spans_txt)}')\n",
    "print(f'Size of dev_spans_txt is {len(dev_spans_txt)}')\n",
    "print(f'Size of test_spans_txt is {len(test_spans_txt)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529233e",
   "metadata": {},
   "source": [
    "##### TFIDF vectorization (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09faf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "vectorizer = vectorizer.fit(train_spans_txt) #It's important to do it on the training data\n",
    "tfidf_features_skl = vectorizer.get_feature_names_out()#vectorizer.get_feature_names()\n",
    "\"\"\"\n",
    "spacy_tfidf_vectorizer = TfidfVectorizer(tokenizer=sentences_custom.get_tokens_spacy,\n",
    "                                         min_df=5,\n",
    "                                         ngram_range=(1,1))\n",
    "spacy_tfidf_vectorizer = spacy_tfidf_vectorizer.fit(train_spans_txt)\n",
    "tfidf_features_skl = spacy_tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tfidf_features_skl)\n",
    "tfidf_features_skl[1000:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_skl = spacy_tfidf_vectorizer.transform(train_spans_txt).toarray()\n",
    "dev_tfidf_skl = spacy_tfidf_vectorizer.transform(dev_spans_txt).toarray()\n",
    "test_tfidf_skl = spacy_tfidf_vectorizer.transform(test_spans_txt).toarray()\n",
    "\n",
    "train_spans_labels = np.array([s['type'] for s in train_spans])\n",
    "dev_spans_labels = np.array([s['type'] for s in dev_spans])\n",
    "test_spans_labels = np.array([s['type'] for s in test_spans])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cd955",
   "metadata": {},
   "source": [
    "##### Examine the top TFIDF values of tokens in a sentence (training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_top_tfidf(train_spans_txt, \n",
    "               train_tfidf_skl,\n",
    "               tfidf_features_skl,\n",
    "               random.randint(0, len(train_spans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065a3c5",
   "metadata": {},
   "source": [
    "##### Examine the top TFIDF values of tokens in a sentence (dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_top_tfidf(dev_spans_txt, \n",
    "               dev_tfidf_skl,\n",
    "               tfidf_features_skl,\n",
    "               random.randint(0, len(dev_spans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f2249",
   "metadata": {},
   "source": [
    "##### Examine the top TFIDF values of tokens in a sentence (test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efea421",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_top_tfidf(test_spans_txt, \n",
    "               test_tfidf_skl,\n",
    "               tfidf_features_skl,\n",
    "               random.randint(0, len(test_spans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71550805",
   "metadata": {},
   "source": [
    "##### Examine features with highest average TFIDF score per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = top_features_by_class(train_tfidf_skl, \n",
    "                            train_spans_labels,\n",
    "                            tfidf_features_skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classSpan in dfs.keys():\n",
    "    print('{0}\\n==>{1}'.format('*'*50, classSpan))\n",
    "    print(dfs[classSpan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"CaseIssue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684bc97",
   "metadata": {},
   "source": [
    "### 5.2 Word Embedding Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077ed66",
   "metadata": {},
   "source": [
    "###### Preparation: mean and standard deviation (of tokens) are gotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugLog(message):\n",
    "    now = datetime.now()\n",
    "    print(now.strftime(\"%H:%M:%S\"), message)\n",
    "\n",
    "def getTxtFromSpan(span):\n",
    "    return span[\"txt\"].lower()\n",
    "\n",
    "def getMeanAndStdDevTokensTraining(spans):\n",
    "    debugLog(\"BEGIN getMeanAndStdDevTokensTraining\")    \n",
    "    \n",
    "    mean = 0.0\n",
    "    std_dev = 0.0\n",
    "    nlp = sentences_custom.getNlpObj()\n",
    "    \n",
    "    #listNumTokens = [len(sentences_custom.get_tokens_spacy(t[\"txt\"], nlp)) for t in train_spans]\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    debugLog(\"To execute map getTxtFromSpan\")\n",
    "    spans_txt = pool.map(getTxtFromSpan, spans)\n",
    "    \n",
    "    debugLog(\"To execute pipe to get SpacyDocuments\")\n",
    "    #spacy.prefer_gpu()\n",
    "    nlp = sentences_custom.getNlpObj()\n",
    "    spacy_docs_from_spans = list(nlp.pipe(spans_txt))\n",
    "    \n",
    "    print(f'Length of spacy_docs_from_spans is {len(spacy_docs_from_spans)}')\n",
    "    \n",
    "    debugLog(\"To execute map get_tokens_spacy_opt\")\n",
    "    #listNumTokens = pool.starmap(sentences_custom.get_tokens_spacy_opt, zip(spacy_docs_from_spans, spans_txt))\n",
    "    listTokens = pool.map(sentences_custom.get_tokens_spacy, spacy_docs_from_spans)\n",
    "    \n",
    "    debugLog(\"Converting npListNumTokens, computing mean, std_dev\")\n",
    "    npListNumTokens = [len(t) for t in listTokens]\n",
    "    npListNumTokens = np.asarray(npListNumTokens, dtype='float32')\n",
    "    \n",
    "    mean = npListNumTokens.mean()\n",
    "    std_dev = npListNumTokens.std()\n",
    "    \n",
    "    listNumTokensNorm = (npListNumTokens-mean)/std_dev\n",
    "    \n",
    "    debugLog(\"Adding tokens_normalized to each span\")    \n",
    "    for span, tokens_norm in zip(spans, listNumTokensNorm):\n",
    "        span[\"tokens_normalized\"] = tokens_norm\n",
    "    \n",
    "    debugLog(\"END getMeanAndStdDevTokensTraining\")    \n",
    "    return mean, std_dev, listNumTokensNorm, listTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std_dev, listNumTokensNorm, listTokens = getMeanAndStdDevTokensTraining(train_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f354919",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean: \", mean)\n",
    "print(\"std_dev: \", std_dev)\n",
    "print(\"Lista num tokens norm: \", len(listNumTokensNorm))\n",
    "print(listTokens[0])\n",
    "print(len(listTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adce34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a05443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectorFeature(tokens, modelFastText):\n",
    "    #print(\"Num tokens =\", len(tokens))\n",
    "    if len(tokens)==0: tokens = [\"\"]\n",
    "    vectors = [modelFastText.get_word_vector(t) for t in tokens]\n",
    "    \n",
    "    vector = np.asarray(vectors, dtype='float32').mean(axis=0)\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515e517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_train_span = [getVectorFeature(t, modelFastText) for t in listTokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2586e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_np = np.asarray(vectorized_train_span, dtype='float32')\n",
    "starts_normalized = np.array([s['start_normalized'] for s in train_spans])\n",
    "tokens_normalized = np.array([s['tokens_normalized'] for s in train_spans])\n",
    "train_y = np.array([s['type'] for s in train_spans])\n",
    "\n",
    "train_X = np.concatenate((vector_np, np.expand_dims(starts_normalized, axis=1)), axis=1)\n",
    "train_X = np.concatenate((train_X, np.expand_dims(tokens_normalized, axis=1)), axis=1)\n",
    "\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(vectorized_span, spans, tokens_normalized=None):\n",
    "    vector_np = np.asarray(vectorized_span, dtype='float32')\n",
    "    starts_normalized = np.array([s['start_normalized'] for s in spans])\n",
    "    if tokens_normalized is None:\n",
    "        tokens_normalized = np.array([s['tokens_normalized'] for s in spans])\n",
    "        \n",
    "    _y = np.array([s['type'] for s in spans])\n",
    "\n",
    "    X = np.concatenate((vector_np, np.expand_dims(starts_normalized, axis=1)), axis=1)\n",
    "    _X = np.concatenate((X, np.expand_dims(tokens_normalized, axis=1)), axis=1)\n",
    "    \n",
    "    return _X, _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dev, std_dev_dev, listNumTokensNorm_dev, listTokens_dev = getMeanAndStdDevTokensTraining(dev_spans)\n",
    "\n",
    "vectorized_dev_span = [getVectorFeature(t, modelFastText) for t in listTokens_dev]\n",
    "\n",
    "dev_x, dev_y = get_x_y(vectorized_dev_span, dev_spans, listNumTokensNorm_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a17ad",
   "metadata": {},
   "source": [
    "### 5.3 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a50473",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a66bc0",
   "metadata": {},
   "source": [
    "##### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vectors_and_labels(spans, tfidf): #vectorizer\n",
    "    # function takes long to execute\n",
    "    # note: we un-sparse the matrix here to be able to manipulate it\n",
    "    #>>tfidf = spacy_tfidf_vectorizer.transform([s['txt'] for s in spans]).toarray()\n",
    "    starts_normalized = np.array([s['start_normalized'] for s in spans])\n",
    "    print(\"starts_normalized.shape = \", tfidf.shape)\n",
    "    print(\"starts_normalized.shape = \", starts_normalized.shape)\n",
    "    y = np.array([s['type'] for s in spans])\n",
    "    X = np.concatenate((tfidf, np.expand_dims(starts_normalized, axis=1)), axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_skl = spacy_tfidf_vectorizer.transform(train_spans_txt).toarray()\n",
    "dev_tfidf_skl = spacy_tfidf_vectorizer.transform(dev_spans_txt).toarray()\n",
    "test_tfidf_skl = spacy_tfidf_vectorizer.transform(test_spans_txt).toarray()\n",
    "\n",
    "train_spans_labels = np.array([s['type'] for s in train_spans])\n",
    "dev_spans_labels = np.array([s['type'] for s in dev_spans])\n",
    "test_spans_labels = np.array([s['type'] for s in test_spans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = tree.DecisionTreeClassifier(max_depth=50) #, splitter=\"random\"\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=100)\n",
    "#clf = LinearSVC(dual=False, max_iter=1000, loss='squared_hinge', penalty='l2', C=50)\n",
    "#clf = LinearSVC(dual=False, max_iter=1000)\n",
    "#clf = LogisticRegression(max_iter=2000)\n",
    "clf = SVC(kernel='poly', degree=3)#SVC(kernel='poly', gamma='auto', degree=4)#SVC(kernel='poly', gamma='scale', degree=3)\n",
    "\n",
    "clf = clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf7f44",
   "metadata": {},
   "source": [
    "##### Assessing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaea322",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(train_X)\n",
    "print('TRAIN:\\n'+classification_report(train_y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9406a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(train_y, prediction, classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d96c78",
   "metadata": {},
   "source": [
    "##### Assessing against dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X, dev_y = make_feature_vectors_and_labels(dev_spans, dev_tfidf_skl)\n",
    "print(dev_tfidf_skl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_X.shape\n",
    "dev_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dev = clf.predict(dev_X)\n",
    "print('DEV:\\n'+classification_report(dev_y, prediction_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc600e83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(dev_y, prediction_dev, classes=list(clf.classes_),\n",
    "#                      title='Confusion matrix for dev data')\n",
    "#plt.show()\n",
    "\n",
    "plot_confusion_matrix_sklearn(clf, dev_X, dev_y, xticks_rotation='vertical')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ec67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "#dump(clf, 'modelPolynomialSvmKernel3.joblib') \n",
    "clf2 = load('modelLinearSvcDualFalseMaxIt1K.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420702ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = make_feature_vectors_and_labels(test_spans, test_tfidf_skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c86d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = clf2.predict(test_X)\n",
    "print('TEST:\\n'+classification_report(test_y, prediction_test))\n",
    "\n",
    "plot_confusion_matrix_sklearn(clf2, test_X, test_y, xticks_rotation='vertical')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(test_spans, len(test_spans)),\n",
    "                  test_tfidf_skl,\n",
    "                  select_pred_label='Evidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b957b0e",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b44b2",
   "metadata": {},
   "source": [
    "##### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0627101",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clf = tree.DecisionTreeClassifier(max_depth=150, splitter=\"best\", criterion=\"gini\")\n",
    "#clf = RandomForestClassifier(n_estimators=143, max_depth=100)\n",
    "#clf = LinearSVC(dual=False, max_iter=553, loss='squared_hinge', penalty='l2', C=1)\n",
    "#clf = LogisticRegression(max_iter=744) \n",
    "clf = SVC(kernel='rbf', gamma='scale', C=4)\n",
    "#clf = NuSVC(nu=3e-3)\n",
    "clf = clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6007c8",
   "metadata": {},
   "source": [
    "##### Assessing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ceb99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('TRAIN:\\n'+classification_report(train_y, clf.predict(train_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eecf01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(train_y, clf.predict(train_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a694d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_emd_dev = clf.predict(dev_x)\n",
    "print('DEV:\\n'+classification_report(dev_y, prediction_emd_dev))\n",
    "\n",
    "plot_confusion_matrix_sklearn(clf, dev_x, dev_y, xticks_rotation='vertical')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b57d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bea8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_rndm = RandomForestClassifier()#random_state=0\n",
    "clf_rndm = LogisticRegression() \n",
    "#clf_rndm = SVC()\n",
    "#clf_rndm = LinearSVC(loss='squared_hinge', penalty='l2')\n",
    "#clf_rndm = tree.DecisionTreeClassifier()\n",
    "np.random.seed(0)\n",
    "\n",
    "param_distributions = {\"max_iter\": randint(200, 1500)}\n",
    "search = HalvingRandomSearchCV(clf_rndm, param_distributions,\n",
    "                               random_state=0).fit(train_X, train_y)\n",
    "search.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb99310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'modelEmbRadKerSVMScaleC4_v2.joblib') \n",
    "clf2 = load('modelEmbRadKerSVMScaleC4_v2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9287a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_test, std_dev_test, listNumTokensNorm_test, listTokens_test = getMeanAndStdDevTokensTraining(test_spans)\n",
    "\n",
    "vectorized_test_span = [getVectorFeature(t, modelFastText) for t in listTokens_test]\n",
    "\n",
    "test_x, test_y = get_x_y(vectorized_test_span, test_spans, listNumTokensNorm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7f043",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_test = clf2.predict(test_x)\n",
    "print('TEST:\\n'+classification_report(test_y, prediction_test))\n",
    "\n",
    "plot_confusion_matrix_sklearn(clf2, test_x, test_y, xticks_rotation='vertical')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in prediction_test: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_errors_embeddings(eval_spans, predictions, \n",
    "                      select_true_label=None, \n",
    "                      select_pred_label=None):\n",
    "    eval_spans_txt = [s['txt'] for s in eval_spans]\n",
    "    eval_spans_labels = [s['type'] for s in eval_spans]\n",
    "    pred_y = predictions\n",
    "    \n",
    "    for i in range(len(eval_spans)):\n",
    "        true_label = eval_spans_labels[i]\n",
    "        pred_label = pred_y[i]\n",
    "        if true_label != pred_label:\n",
    "            if select_true_label and true_label != select_true_label: continue\n",
    "            if select_pred_label and pred_label != select_pred_label: continue\n",
    "            doc_name = documents_by_id[eval_spans[i]['document']]['name']\n",
    "            print('sentence # '+str(i)+' / case '+doc_name+' / @'+str(eval_spans[i]['start']))\n",
    "            print('pred: '+pred_label+' / true: '+true_label)\n",
    "            print(eval_spans[i]['txt'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b792c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors_embeddings(\n",
    "                  dev_spans,\n",
    "                  prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a850f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
